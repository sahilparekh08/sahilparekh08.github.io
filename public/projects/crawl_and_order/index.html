<!DOCTYPE html>
<html lang="en">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  
    <title>Crawl And Order, a Distributed Search Engine :: Sahil Parekh</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Crawl and Order is a scalable, cloud-based search engine. The system is designed to efficiently handle user queries and deliver relevant search results. It consists of four major components:
Crawler: Crawls the web and fetches pages. Indexer: Builds an inverted index from the crawled pages. PageRank: Ranks pages based on their importance. Ranker: Queries the inverted index and the pagerank results to compute a final score for every relevant URL and order them in decreasing order of relevance. Frontend: Provides a user-friendly interface to perform web search and image search. Under the hood, the project is built on a scalable distributed Key-Value storage which exposes simple operations like GET, PUT and DELETE. Interaction with the KV store is through a distributed computational framework called Flame, which is similar in its functionality to Apache Spark.
" />
<meta name="keywords" content="" />
<meta name="robots" content="noodp" />
<link rel="canonical" href="//localhost:1313/projects/crawl_and_order/" />




<link rel="stylesheet" href="//localhost:1313/assets/style.css">

  <link rel="stylesheet" href="//localhost:1313/assets/blue.css">






<link rel="apple-touch-icon" href="//localhost:1313/img/apple-touch-icon-192x192.png">

  <link rel="shortcut icon" href="//localhost:1313/img/favicon/blue.png">



<meta name="twitter:card" content="summary" />

  
    <meta name="twitter:site" content="" />
  
    <meta name="twitter:creator" content="" />



<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="Crawl And Order, a Distributed Search Engine">
<meta property="og:description" content="Crawl and Order is a scalable, cloud-based search engine. The system is designed to efficiently handle user queries and deliver relevant search results. It consists of four major components:
Crawler: Crawls the web and fetches pages. Indexer: Builds an inverted index from the crawled pages. PageRank: Ranks pages based on their importance. Ranker: Queries the inverted index and the pagerank results to compute a final score for every relevant URL and order them in decreasing order of relevance. Frontend: Provides a user-friendly interface to perform web search and image search. Under the hood, the project is built on a scalable distributed Key-Value storage which exposes simple operations like GET, PUT and DELETE. Interaction with the KV store is through a distributed computational framework called Flame, which is similar in its functionality to Apache Spark.
" />
<meta property="og:url" content="//localhost:1313/projects/crawl_and_order/" />
<meta property="og:site_name" content="Sahil Parekh" />

  
    <meta property="og:image" content="//localhost:1313/img/favicon/blue.png">
  

<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">


  <meta property="article:published_time" content="2024-12-13 00:00:00 &#43;0000 UTC" />












</head>
<body class="blue">


<div class="container center headings--one-size">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="/">
  <div class="logo">
    Sahil Parekh
  </div>
</a>

    </div>
    
      <div class="menu-trigger">menu</div>
    
  </div>
  
    <nav class="menu">
  <ul class="menu__inner menu__inner--desktop">
    
      
        
          <li><a href="/about">About</a></li>
        
      
        
          <li><a href="/experience">Experience</a></li>
        
      
        
          <li><a href="/projects">Projects</a></li>
        
      
        
          <li><a href="/connect">Connect</a></li>
        
      
        
          <li><a href="https://sahilparekh08.github.io/resume.pdf">Resume</a></li>
        
      
      
    

    
  </ul>

  <ul class="menu__inner menu__inner--mobile">
    
      
        <li><a href="/about">About</a></li>
      
    
      
        <li><a href="/experience">Experience</a></li>
      
    
      
        <li><a href="/projects">Projects</a></li>
      
    
      
        <li><a href="/connect">Connect</a></li>
      
    
      
        <li><a href="https://sahilparekh08.github.io/resume.pdf">Resume</a></li>
      
    
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
<div class="post">
  <h1 class="post-title">
    <a href="//localhost:1313/projects/crawl_and_order/">Crawl And Order, a Distributed Search Engine</a></h1>
  <div class="post-meta">
    
      <span class="post-date">
        2024-12-13
        
          [Updated: 2024-12-13]
        
      </span>
    
    
    
  </div>

  
  


  

  <div class="post-content"><div>
        <p><strong>Crawl and Order</strong> is a scalable, cloud-based search engine. The system is designed to efficiently handle user queries
and deliver relevant search results. It consists of four major components:</p>
<ol>
<li><strong>Crawler</strong>: Crawls the web and fetches pages. <!-- raw HTML omitted --></li>
<li><strong>Indexer</strong>: Builds an inverted index from the crawled pages. <!-- raw HTML omitted --></li>
<li><strong>PageRank</strong>: Ranks pages based on their importance. <!-- raw HTML omitted --></li>
<li><strong>Ranker</strong>: Queries the inverted index and the pagerank results to compute a final score for every relevant URL and order them in decreasing order of relevance. <!-- raw HTML omitted --></li>
<li><strong>Frontend</strong>: Provides a user-friendly interface to perform web search and image search. <!-- raw HTML omitted --></li>
</ol>
<p>Under the hood, the project is built on a scalable distributed Key-Value storage which exposes simple operations like GET, PUT and DELETE. Interaction with the KV store is through a distributed computational framework called Flame, which is similar in its functionality to Apache Spark.</p>
<p>One can submit a Job (such as crawler.jar) to the Flame Coordinator, which will then distribute the job to multiple Flame Workers. The workers will then fetch the data from the KV store (interacting with the KVS Coordinator and subsequently with relevant KVS Workers), process it according to the functions and lambdas specified by the submitted job and write the results back to the KV store. The KV store is also responsible for storing the intermediate results of the computation.</p>
<p>The most fundamental unit of computation of the Flame framework are FlameRDDs and FlamePairRDDs. The framework also exposes functions on these RDDs such as map, mapToPair, flatMap, flatMapToPair, foldByKey, filter, join, etc. which can be used to perform complex distributed computations.</p>
<p>Communication between the components is done using the HTTP protocol. All the components run a multithreaded HTTP webserver to process requests. The KV Store persists data in Protobuf format.</p>
<p><img src="/projects/crawl_and_order/arch.jpg" alt="System Architecture"></p>
<p><img src="/projects/crawl_and_order/high_level_approach.png" alt="High Level Flow"></p>
<p><img src="/projects/crawl_and_order/home_page.png" alt="Home Page"></p>
<p>GitHub Repo: <a href="https://github.com/sahilparekh08/Crawl-And-Order">Crawl-And-Order</a></p>
<p>NOTE: This project was a part of the course CIS 5550: Internet and Web Systems (Fall 2024), University of Pennsylvanai</p>

      </div></div>

  

  

</div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>Â© 2024 Powered by <a href="http://gohugo.io">Hugo</a></span>
    
        <span>:: Theme made by <a href="https://twitter.com/panr">panr</a></span>
      </div>
  </div>
</footer>

<script src="//localhost:1313/assets/main.js"></script>
<script src="//localhost:1313/assets/prism.js"></script>







  
</div>

</body>
</html>
